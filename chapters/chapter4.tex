\chapter{Методология}
\label{chap:methodology}
\chaptermark{Методология}

В данной главе описывается структура бенчмарка и представлены количественные критерии оценки методов тензорного разложения, включающие:
\begin{itemize}
    \item использование памяти различными компонентами вычислений,
    \item ошибку Фробениуса,
    \item время вычислений.
\end{itemize}
Рассматриваются типы тензорных данных, особенности их представления, а также процедуры выбора параметров разложения. Особое внимание уделяется методам оптимизации ранга для разложений Тукера и Тензорного Поезда (Tensor Train, TT). Также описан алгоритм сжатия нейронных сетей и внедрённые улучшения.

\section{Типы тензорных данных для бенчмарка}
\label{sec:tensor_data_types_for_benchmark}

В этой секции представлены используемые типы тензорных данных и их конкретные примеры, применяемые для оценки и сравнения методов и библиотек тензорного разложения. Примеры демонстрируют возможности и сферу применения методов разложения.

\subsection*{Изображения}

Изображения представлены трёхмерными тензорами с размерами, соответствующими высоте, ширине и цветовым каналам (RGB). Данные загружаются из распространённых форматов (jpg, png) с помощью библиотеки OpenCV-Python.

Для бенчмарка выбраны три варианта изображений с разными размерами и аспектами:
\begin{itemize}
    \item среднее изображение с размером (564, 564, 3),
    \item изображение с другим соотношением сторон (412, 620, 3),
    \item крупное изображение с высоким разрешением (689, 1195, 3).
\end{itemize}

Такие данные позволяют оценить влияние размера, соотношения сторон и цветовой палитры на качество и производительность методов тензорного разложения.

\subsection*{Видео}

Видео рассматриваются как четвёртого порядка тензоры \(\mathcal{X} \in \mathbb{R}^{T \times H \times W \times 3}\), где \(T\) — число кадров, \(H\) и \(W\) — высота и ширина кадра соответственно, 3 — количество цветовых каналов RGB.

Для бенчмарка выбраны три видеоролика с различной длительностью и пространственным разрешением, загруженные с YouTube и обработанные через OpenCV-Python. Выбор сделан с учётом ограничения вычислительных ресурсов, чтобы обеспечить воспроизводимость экспериментов.

\subsection*{ЭЭГ (электроэнцефалография)}

Для тестирования методов на тензорах высокого порядка использованы два набора данных ЭЭГ:

\begin{itemize}
    \item \textbf{EEG Motor Movement/Imagery Dataset} \cite{Schalk2004BCI2000} — шестимерный тензор с размерностями, отражающими субъектов, запуски экспериментов, типы событий, эпизоды, каналы и временные отсчёты. Использованы данные четырёх субъектов и двенадцати запусков для сохранения вариативности и управляемости вычислений.
    \item \textbf{LIMO dataset} — данные, доступные в библиотеке MNE-Python, содержащие тензор с пятью измерениями, включающими субъектов, запуски, испытания, события и временные отсчёты. Размеры были усечены до общих для всех субъектов значений для обеспечения однородности.
\end{itemize}

\section{Оптимальный выбор ранга для разложений Тукера и Tensor Train}
\label{sec:rank_selection_methodology}

Выбор ранга является ключевым в тензорных разложениях, так как определяет компромисс между степенью сжатия и ошибкой аппроксимации. Задача формулируется как ограниченная задача оптимизации, решаемая с помощью локальных и глобальных алгоритмов минимизации из пакета \texttt{SciPy} с использованием разложений из \texttt{TensorLy}.

\subsection*{Ограничения на ранги}

\paragraph{Tensor Train.} Для каждого внутреннего ранга \(r_k\) действуют классические ограничения:
\[
1 \le r_k \le \min\left(\prod_{i=1}^k I_i,\; \prod_{j=k+1}^N I_j\right), \quad k=1,\dots,N-1,
\]
где \(\mathcal{X} \in \mathbb{C}^{I_1 \times \dots \times I_N}\) — исходный тензор, \(I_k\) — размерность \(k\)-го моды, \(r_k\) — \(k\)-й TT-ранг, \(N\) — порядок тензора. Внешние ранги фиксированы: \(r_0 = r_N = 1\).

\paragraph{Tucker.} Для разложения Тукера ранги выбираются для каждого измерения:
\[
1 \le r_n \le I_n, \quad n=1,\dots,N,
\]
где \(r_n\) — ранг Тукера вдоль \(n\)-й моды.

\subsection*{Функция потерь}

Для каждой комбинации рангов строится приближение исходного тензора, после чего оцениваются два параметра:

\begin{enumerate}
    \item Относительная ошибка Фробениуса — отношение нормы разности исходного и приближённого тензоров к норме исходного.
    \item Коэффициент сжатия — отношение объёма памяти, занимаемого факторами разложения, к объёму памяти исходного тензора.
\end{enumerate}

Оптимизация сводится к поиску рангов, минимизирующих комбинацию этих показателей с учётом баланса между точностью и сжатием.

\section{Сжатие нейронных сетей}

Для демонстрации практического применения методов тензорного разложения реализован алгоритм сжатия сверточной нейронной сети. Внедрены улучшения, направленные на повышение эффективности сжатия без существенной потери качества.

---

Таким образом, методология включает разработку комплексного бенчмарка, описывающего разнообразные типы данных, строгие критерии оценки и алгоритмические подходы к оптимальному выбору ранга в задачах тензорного сжатия и аппроксимации.
