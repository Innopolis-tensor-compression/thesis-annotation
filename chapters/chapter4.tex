\chapter{Методология}
\label{chap:methodology}
\chaptermark{Методология}

\textbf{Цель методики} — разработать воспроизводимый бенчмарк, сравнивающий тензорные разложения и их реализации с точки зрения \emph{времени, памяти и точности} и одновременно предоставить алгоритм автоматического выбора ранга, пригодный для сжатия как данных, так и слоёв нейросетей.

\subsection*{Корпус тензоров}
\begin{itemize}\setlength\itemsep{0.15em}
    \item \emph{Изображения} — три RGB-тензора формата \((H,W,3)\) c разрешением $412\!\times\!620$–$689\!\times\!1195$ пикс.  
    \item \emph{Видео} — три 4-х мерных тензора \((T,H,W,3)\) с короткими роликами ($T\le 237$ кадров) для проверки влияния временного измерения.  
    \item \emph{EEG} — два 6-ти мерных тензора, включающие факторы «субъект», «сеанс», «событие», «эпоха», «канал», «время» (до $4{\small\times}12{\small\times}2{\small\times}15{\small\times}64{\small\times}1281$).  Используются для стресс-теста высокой размерности.
\end{itemize}

\subsection*{Критерии оценки}
\begin{itemize}\setlength\itemsep{0.15em}
    \item \textbf{Пиковое потребление памяти} (RAM/VRAM).  
    \item \textbf{Время исполнения} алгоритма.  
    \item \textbf{Относительная ошибка Фробениуса} между оригиналом и реконструкцией.  
    \item Для нейросетей — \textbf{потеря точности} на валидации.
\end{itemize}

\subsection*{Алгоритм выбора ранга}
Ранг $(\mathbf r)$ ищется как минимум функции  
\[
\mathcal{L}(\mathbf r)=
\alpha\,\varepsilon_F(\mathbf r)+
\beta\,(\rho_{\text{target}}-\rho_{\text{actual}}(\mathbf r))^{2},
\]
где $\varepsilon_F$ — нормированная ошибка Фробениуса,  
$\rho$ — доля памяти (цель — $50\%$ от исходного объёма).  
Ограничения на TT-ранги $r_k$ и Tucker-ранги $R_n$ задаются классическими верхними/нижними границами.  
Поиск ведётся пакетами \texttt{SciPy} (Nelder–Mead, Powell, SLSQP, дифференциальная эволюция) плюс кастомный локальный оптимизатор; выбирается наименьшая $\mathcal{L}$.

\subsection*{Дизайн бенчмарка}
\begin{enumerate}\setlength\itemsep{0.15em}
    \item Для каждого тензора вызывается процедура выбора ранга (Tucker или TT) под целевое сжатие $0.5$.  
    \item Выполняются разложения из \texttt{TensorLy} и \texttt{T3F}.  
    \item Регистрируются время, пиковая память, ошибка.  
    \item Сравнение проводится отдельно по Dense, Sparse и Block-Sparse форматам при наличии поддержки в библиотеке.
\end{enumerate}

\subsection*{Компрессия нейронных сетей}
На основе работы \cite{stable_low_rank_tensor_decomposition} реализован конвейер в PyTorch:
\begin{enumerate}\setlength\itemsep{0.15em}
    \item автоматический выбор слоёв (conv и transposed-conv),  
    \item применение CP, Tucker или гибрид CP+Tucker к~фильтрам,  
    \item интеграция алгоритма ранга для соблюдения заданного $\rho_{\text{target}}$,  
    \item тонкая доводка (fine-tuning) сети.  
\end{enumerate}
Тестовые архитектуры (VGG-16, ResNet-18/50) показывают сокращение параметров в $4$–$8\times$ при падении точности ${\le}1{\,}\%$ на ImageNet, подтверждая пригодность методики.

\textbf{Итог.} Методология обеспечивает репрезентативную оценку разложений на тензорах 3D–6D и демонстрирует практическую ценность адаптивного выбора ранга для компрессии как данных, так и глубоких моделей.