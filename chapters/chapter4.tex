\chapter{Методология}
\label{chap:methodology}
\chaptermark{Методология}

В данной главе представлена методология, охватывающая разработку: (1) бенчмарка реализаций методов тензорной декомпозиции, (2) алгоритма автоматического выбора ранга для декомпозиций Tucker и Tensor Train, а также (3) алгоритма аппроксимации нейронных сетей.

\subsection*{Корпус тензоров для бенчмарка}
\begin{itemize}\setlength\itemsep{0.15em}
    \item \emph{Изображения} — три RGB-тензора формата \((H,W,3)\): $564\times564\times3$, $412\times620\times3$ и $689\times1195\times3$.  
    \item \emph{Видео} — три 4-х мерных тензора \((T,H,W,3)\): $220\times256\times144\times3$, $100\times144\times192\times3$ и $237\times144\times256\times3$.  
    \item \emph{EEG} — два 6-ти мерных тензора, включающие факторы «субъект», «сеанс», «событие», «эпоха», «канал», «время»: $4\times12\times2\times15\times64\times1281$ и $3\times1\times1050\times2\times132\times201$.
\end{itemize}

\subsection*{Алгоритм выбора ранга}
Ранг $(\mathbf r)$ ищется как минимум функции  
\begin{equation}
    \label{eq:loss_function_select_rank}
\mathcal{L}(\mathbf r)=
\alpha\,\varepsilon_F(\mathbf r)+
\beta\,(\rho_{\text{target}}-\rho_{\text{actual}}(\mathbf r))^{2},
\end{equation}
где $\varepsilon_F$ — нормированная ошибка Фробениуса,  
$\rho$ — доля памяти (цель — $50\%$ от исходного объёма).  
Ограничения на TT-ранги $r_k$ и Tucker-ранги $R_n$ задаются классическими верхними/нижними границами.  
Поиск ведётся пакетами \texttt{SciPy} (Nelder–Mead, Powell, SLSQP, differential\_evolution) плюс кастомный локальный оптимизатор; выбирается наименьшая $\mathcal{L}$.

\subsection*{Сравнение методов тензорной декомпозиции}

\subsubsection*{Сравнение по качественным критериям}
Производится ручное сравнение представленных в работе~\cite{tensor_software_landscape} реализаций, по критериям: поддерживаемые форматы тензоров, аппаратная поддержка, поддерживаемые языки, доступность.

\subsubsection*{Дизайн бенчмарка}
Для каждого тензора вызывается процедура выбора ранга (для Tucker или TT) под целевое сжатие $0.5$; Запускается расчет аппроксимации и реконструкции на основе реализаций методов декомпозиции представленых в \texttt{TensorLy} и \texttt{T3F}; Регистрируются время, пиковая память, ошибка Фробениуса.

\subsubsection*{Сравнение по количественным критериям}
На основе зарегистрированных логов бенчмарка проводится сравнение реализаций методов тензорной декомпозиции по следующим критериям: пиковое потребление VRAM и RAM, затраченное время и ошибка Фробениуса.

\subsection*{Аппроксимации нейронных сетей}
На основе работы \cite{stable_low_rank_tensor_decomposition} воспроизводится и улучшается метод аппроксимации нейронных сетей в PyTorch: автоматический выбор слоёв (conv и transposed-conv); применение CP, Tucker или гибрид CP+Tucker к~фильтрам; интеграция алгоритма ранга для соблюдения заданного $\rho_{\text{target}}$; дообучение сети.