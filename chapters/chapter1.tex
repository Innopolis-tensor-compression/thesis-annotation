\chapter{Введение}
\label{chap:intro}

\chaptermark{Введение}

Методы тензорных разложений находят широкое применение в анализе многомерных данных, машинном обучении и сжатии нейронных сетей \cite{tensor_decompositions_for_data_science, tensor_computation_for_data_analysis}. Они позволяют эффективно аппроксимировать многомерные структуры путём удаления малозначимой информации и сокращения объёма занимаемой памяти. Однако остаются нерешённые задачи, связанные с выбором оптимальных методов разложения и соответствующих параметров.

Существует множество библиотек, реализующих различные методы тензорных разложений: Tucker \cite{tensorly_parafac_tucker}, Tensor-Train (TT) \cite{tensorly_tensor_train}, PARAFAC \cite{tensorly_parafac_tucker, tensorly_parafac_2, tensorly_parafac_3, tensor_decompositions_for_data_science, tensor_computation_for_data_analysis} и RTPCA \cite{rtpca_method}. Эффективность каждого из них варьируется в зависимости от структуры и размерности данных, а также от конкретных задач. Одной из ключевых проблем остаётся выбор ранга разложения, напрямую влияющего на точность аппроксимации и степень сжатия.

Целью данной работы является проведение комплексного теоретического и эмпирического анализа методов тензорных разложений на различных типах данных (изображения, видеопоследовательности, ЭЭГ-сигналы), а также исследование их применимости к сжатию глубоких нейронных сетей.

В рамках работы были поставлены следующие задачи:
\begin{enumerate}
  \item Провести бенчмарк современных Python-библиотек тензорных разложений по времени исполнения, потребляемой памяти и ошибке восстановления на представительных тензорах размерностей 3D, 4D и 6D;
  \item Разработать практические рекомендации по выбору методов и инструментов разложения с учётом типов данных, особенностей API, языков программирования и метрик эффективности (ошибка Фробениуса, время, память);
  \item Спроектировать алгоритм автоматического подбора рангов для форматов Tucker и Tensor-Train, обеспечивающий заданное пользователем сжатие при минимальной ошибке;
  \item Интегрировать предложенный алгоритм ранжирования в расширенный пайплайн для сжатия свёрточных и полносвязных слоёв нейронных сетей с реализацией на Python;
  \item Оценить разработанный пайплайн на стандартных архитектурах CNN, проанализировать компромиссы между точностью и сжатием, определить направления для дальнейшей оптимизации.
\end{enumerate}

Вклад авторов распределён следующим образом. Оба автора совместно провели начальный обзор литературы по тензорной алгебре и методам разложения (глава~\ref{chap:lr}). 

\textbf{Григорий Нестеров}: систематизировал теоретическую часть обзора, реализовал бенчмарк, разработал алгоритм выбора рангов для Tucker и TT, провёл эмпирическое исследование на разнообразных типах данных (главы~\ref{chap:implementation},~\ref{chap:eval}). 

\textbf{Александр Ващенко}: изучил применение тензорных разложений для сжатия нейросетей, расширил существующий метод сжатия слоя с учётом автоматического ранжирования, реализовал конечное решение и провёл его экспериментальную оценку (главы~\ref{chap:implementation},~\ref{chap:eval}).

Оба автора обсуждали полученные результаты и согласовали финальную версию работы.

Структура работы:
\begin{itemize}
  \item Глава~\ref{chap:preliminaries}: основные понятия тензорной алгебры и форматы представления тензоров.
  \item Глава~\ref{chap:lr}: обзор классических и современных методов разложения, включая их теоретические основы и практические применения.
  \item Глава~\ref{chap:methodology}: описание типов данных, используемых в бенчмарке, методологии эксперимента и подхода к выбору оптимального ранга.
  \item Глава~\ref{chap:implementation}: технические детали реализации алгоритмов, описания пайплайна и используемых библиотек.
  \item Глава~\ref{chap:eval}: оценка эффективности решений, обсуждение полученных результатов и выявленных ограничений.
  \item Глава~\ref{chap:conclusion}: выводы о наилучших методах и условиях их применения, ограничения и перспективы дальнейших исследований.
\end{itemize}
