\chapter{Реализация}
\label{chap:implementation}
\chaptermark{Реализация}

В данной главе описывается реализация ключевых компонентов исследования, включая подготовку данных для бенчмарка, выбор параметров разложения и алгоритмы оптимизации ранга для тензорных разложений. Особое внимание уделено методам оценки качества и эффективности сжатия.

\section{Типы тензорных данных для бенчмарка}

В качестве тестовых данных использовались несколько типов тензоров, отражающих разнообразие реальных задач и проверяющих устойчивость методов разложения.

\subsection*{Изображения}

Изображения представлены трехмерными тензорами с размерностями по высоте, ширине и цветовым каналам (RGB). Для экспериментов использованы изображения с различным разрешением и соотношением сторон, что позволяет проверить адаптивность методов к разным визуальным характеристикам.

\subsection*{Видео}

Видео рассматриваются как тензоры четвёртого порядка с измерениями: количество кадров, высота, ширина и цветовые каналы. Для бенчмарка были выбраны короткие видео с разными пространственно-временными параметрами, чтобы балансировать вычислительную нагрузку и разнообразие данных.

\subsection*{Электроэнцефалограммы (ЭЭГ)}

Для тестирования методов на высокоразмерных тензорах применялись ЭЭГ-данные из публичных наборов \cite{Schalk2004BCI2000}. Эти данные имеют шесть размерностей, отражающих субъектов, прогоны, события, эпохи, каналы и временные сэмплы, что создаёт значительную нагрузку на память и вычисления.

\section{Выбор оптимального ранга для разложений Tucker и Tensor-Train}

Определение ранга разложения критично для баланса между степенью сжатия и точностью аппроксимации. Задача формулируется как ограниченная оптимизация параметров ранга с использованием методов из \texttt{TensorLy} и алгоритмов минимизации из \texttt{SciPy}.

\subsection*{Ограничения на ранги}

Для Tensor-Train ранги \(r_k\) ограничены классическими условиями:
\[
1 \le r_k \le \min \left(\prod_{i=1}^k I_i, \prod_{j=k+1}^N I_j\right), \quad k=1,\dots,N-1,
\]
где \(I_i\) — размерность \(i\)-го моды исходного тензора, что гарантирует корректность вычислений.

Для Tucker разложения ранги могут свободно варьироваться по каждой моде в пределах:
\[
1 \le r_n \le I_n, \quad n=1,\dots,N.
\]

\subsection*{Функция потерь}

Для каждого набора рангов вычисляется приближение исходного тензора, после чего оцениваются две метрики:

\begin{enumerate}
    \item Относительная ошибка Фробениуса между исходным и восстановленным тензорами.
    \item Коэффициент сжатия, измеряющий отношение памяти, занятой факторами разложения, к объему исходного тензора.
\end{enumerate}

Оптимизация направлена на минимизацию функции потерь, учитывающей компромисс между точностью и степенью сжатия.

\section{Дополнительно: алгоритм сжатия нейросетей}

Также реализован алгоритм сжатия нейросетей, основанный на тензорных разложениях, который улучшен с учётом специфики выбранных методов и параметров ранга. Детали алгоритма и его влияние на производительность будут представлены далее.

% Конец главы
