\chapter{Анализ результатов}
\label{chap:eval}
\chaptermark{Анализ результатов}

В текущей главе представлен анализ результатов по исследованным темам (1) точность алгоритма автоматического выбора ранга, (2) производительность популярных библиотек тензорных разложений и (3) эффективность предложенного метода сжатия нейронных сетей.

\subsection*{Алгоритм выбора ранга для Tucker и Tensor-Train}
Для трёх тестовых RGB-тензоров (3-го порядка) сравнены пять оптимизаторов. \emph{Дифференциальная эволюция} оказалась наилучшей по совокупности критериев: при целевом сжатии 50 \% она обеспечила: среднюю относительную ошибку Фробениуса ${<}\,1\%$ (0.01 \% для наиболее «цветового» изображения); время подбора ранга 39–51 с против 94 с у координатного поиска и 28–58 с у Powell при худшей точности; надёжную сходимость без «залипаний» в начальном ранге, наблюдавшихся у Nelder–Mead и SLSQP.

Таким образом, сформулированная задача минимизации комбинированного функционала (ошибка Фробениуса + штраф за отклонение от заданного коэффициента сжатия) успешно решена; итоговый метод поиска ранга для форматов Tucker и TT опубликован в репозитории.

\subsection*{Бенчмарк реализаций методов тензорной декомпозиции}
Комплексный бенчмарк (10\,158 уникальных запусков; тензоры 3D–6D) охватывал TensorLy 0.9.0, T3F 1.2.0. Ключевые выводы:
\begin{itemize}\setlength\itemsep{0.2em}
    \item \textbf{TensorLy + Tensor-Train} показал наилучший баланс «точность – память – время»: ошибка Фробениуса 0.0002–0.48 \%, ускорение до 5× по сравнению с CP/Tucker, память <=3 ГБ для 3D и <=5.5 ГБ для 6D.
    \item \textbf{CP/PARAFAC} превосходил по ошибке (до 0.3 \%) лишь на мелких 3D-тензорах, но требовал {\raise.17ex\hbox{$\scriptstyle\sim$}}2× больше памяти и 5× больше времени.
    \item Основные \emph{ошибки по памяти} (50 \% неудачных прогонов) вызваны комбинациями \texttt{init=svd} у TensorLy CP, \texttt{svd=symeig\_svd} у TensorLy TT или \texttt{init=svd} и \texttt{svd=symeig\_svd} у TensorLy Tucker; переход к \texttt{init=random} и \texttt{svd=truncated\_svd} устраняет проблему без потери качества.
\end{itemize}
Итоговые рекомендуемые парметры:  
\emph{TT (truncated\_svd)}, \emph{Tucker (init=random, svd=randomized\_svd)} и \emph{CP (init=random, cvg\_criterion=rec\_error, $l_2$-reg.=0.5)}.

\subsection*{Сжатие слоев нейронных сетей}
Метод на основе PyTorch применён к шести моделям ImageNet (ResNet-18/34/50, VGG-11/16/19); все свёрточные и обратные свёрточные слои заменены Tucker-ядрами с автоматическим подбором ранга.
\begin{itemize}\setlength\itemsep{0.2em}
    \item \textbf{Сжатие параметров}: 4-8x (30 \% от исходного веса).
    \item \textbf{Скорость инференса}: ускорение 14–22 \%.  
    \item \textbf{Точность}: после 1 эпохи дообучения потери <= 1 pp Top-1; для ResNet-18/34 точность даже выросла на ${\approx} 2\,\%$ благодаря лёгкому регуляризующему эффекту разложения.
\end{itemize}

\subsection*{Ключевые выводы}
\begin{enumerate}\setlength\itemsep{0.2em}
    \item Дифференциальная эволюция предпочтительны для оптимизации рангов для Tucker и Tensor-Train.  
    \item TensorLy-TT — практический стандарт в рамках рассмотренных реализаций для разнотипных тензоров; CP оправдан лишь при строгих требованиях к интерпретируемости на малых данных.  
    \item Интеграция автоматического ранга в метод сжатия слоев нейронных сетей позволяет получать компактные модели без ручного подбора гиперпараметров и без существенного ухудшения метрик.
\end{enumerate}

\textbf{Перспективы.} Для улучшения есть возможность изучить гибриды «глобальный поиск + локальное доулучшение», GPU-ускоренные версии оптимизаторов ранга и дополнительные функции потерь, учитывающие структурные свойства данных.  

Все графики, логи и ноутбуки доступны по ссылке:  
\url{https://github.com/Innopolis-tensor-compression/tensor-compression-methods}.