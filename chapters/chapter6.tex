\chapter{Анализ результатов}
\label{chap:eval}
\chaptermark{Анализ результатов}

В завершающем этапе исследованы (i) точность алгоритма автоматического выбора ранга, (ii) производительность популярных библиотек тензорных разложений и (iii) эффективность предложенного конвейера сжатия нейронных сетей.

\subsection*{Алгоритм выбора ранга}
Для трёх тестовых RGB-тензоров (3-го порядка) сравнены пять оптимизаторов. \emph{Дифференциальная эволюция} оказалась наилучшей по совокупности критериев: при целевом сжатии 50 \% она обеспечила
\begin{itemize}\setlength\itemsep{0.2em}
    \item среднюю относительную ошибку Фробениуса ${<}\,1\%$ (0.01 \% для наиболее «цветового» изображения);
    \item время подбора ранга 39–51 с против 94 с у координатного поиска и 28–58 с у Powell при худшей точности;
    \item надёжную сходимость без «залипаний» в ранге $[1,1,1,1]$, наблюдавшихся у Nelder–Mead и SLSQP.
\end{itemize}
Таким образом, сформулированная задача минимизации комбинированного функционала (ошибка + штраф за отклонение от заданного коэффициента сжатия) успешно решена; итоговый модуль rank search для форматов Tucker и TT опубликован в репозитории.

\subsection*{Бенчмарк библиотек}
Комплексный бенчмарк (10\,158 запусков; тензоры 3D–6D) охватывал TensorLy 0.9.0, T3F 1.2.0 и несколько альтернатив / устаревших пакетов. Ключевые выводы:
\begin{itemize}\setlength\itemsep{0.2em}
    \item \textbf{TensorLy + Tensor-Train} показал наилучший баланс «точность – RAM/VRAM – время»: ошибка 0.0002–0.48 \%, ускорение до 5× по сравнению с CP/Tucker, память <=3 ГБ для 3D и <=5.5 ГБ для 6D.
    \item \textbf{CP/PARAFAC} превосходил по ошибке (до 0.3 \%) лишь на мелких 3D-тензорах, но требовал {\raise.17ex\hbox{$\scriptstyle\sim$}}2× больше памяти и 5–20× больше времени.
    \item Основные \emph{OOM-срывы} (50 \% неудачных прогонов) вызваны комбинациями \texttt{init=svd} или \texttt{svd=symeig\_svd}; переход к \texttt{init=random}\texttt{svd=truncated\_svd} устраняет проблему без потери качества.
\end{itemize}
Практические рекомендации:  
\emph{TT (Truncated SVD)}, \emph{Tucker (init=random, svd=randomized\_svd)} и \emph{CP (init=random, cvg\_criterion=rec\_error, $l_2$-рег.=0.5)}.

\subsection*{Сжатие нейронных сетей}
Конвейер PyTorch применён к шести моделям ImageNet (ResNet-18/34/50, VGG-11/16/19); все свёрточные и обратные свёрточные слои заменены Tucker-ядрами с автоматическим рангом.
\begin{itemize}\setlength\itemsep{0.2em}
    \item \textbf{Сжатие параметров}: 4-8x (30 \% от исходного веса).
    \item \textbf{Скорость инференса}: ускорение 14–22 \%.  
    \item \textbf{Точность}: после 1 эпохи fine-tuning потери <= 1 pp Top-1; для ResNet-18/34 точность даже выросла на ${\approx} 2\,\%$ благодаря лёгкому регуляризующему эффекту разложения.
\end{itemize}

\subsection*{Ключевые выводы}
\begin{enumerate}\setlength\itemsep{0.2em}
    \item Глобальные стохастические схемы (дифференциальная эволюция) предпочтительны для дискретной оптимизации рангов.  
    \item TensorLy-TT — практический стандарт де-факто для разнотипных тензоров; CP оправдан лишь при строгих требованиях к интерпретируемости на малых данных.  
    \item Интеграция автоматического ранга в pipeline DL-сжатия позволяет получать компактные модели без ручного подбора гиперпараметров и без существенного ухудшения метрик.
\end{enumerate}

\textbf{Перспективы.} Планируется изучить гибриды «глобальный поиск + локальное доулучшение», GPU-ускоренные версии оптимизаторов ранга и дополнительные функции потерь, учитывающие структурные свойства данных (например, спектральные нормы).  
Все отчёты, журналы и ноутбуки доступны по адресу:  
\url{https://github.com/Innopolis-tensor-compression/tensor-compression-methods}.