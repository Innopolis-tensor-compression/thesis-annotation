\chapter{Заключение}
\label{chap:conclusion}
\chaptermark{Заключение}

Работа обобщает результаты систематического исследования тензорных разложений для трёх классов данных (изображения, видео и ЭЭГ) и их применения к сжатию глубинных нейросетей. Решены все поставленные в начале задачи.

\textbf{Основные достижения.}
\begin{enumerate}\setlength\itemsep{0.3em}
    \item \emph{Качественный обзор} \,> 30 библиотек; сформирован краткий «шорт-лист» Python-инструментов (TensorLy, T3F), пригодных для воспроизводимых экспериментов.
    \item \emph{Бенчмарк 10 000+ прогонов} на 3D–6D тензорах: измерены время, пиковая RAM/VRAM и ошибка Фробениуса. Выявлено, что TensorLy-TT обеспечивает оптимальный баланс точности и ресурсов; даны практические настройки гиперпараметров для CP, Tucker и TT.
    \item Разработан \emph{автоматический выбор ранга} для форматов Tucker и Tensor-Train. Алгоритм на базе дифференциальной эволюции гарантирует заданное сжатие (50 \%) при минимальной ошибке; опубликован модуль \texttt{rank\_search}.
    \item Воссоздан и улучшен \emph{конвейер сжатия CNN}. Для VGG и ResNet получено 4–8x уменьшение параметров и 14–22 \% ускорение инференса при падении Top-1 не более 1 pp (часто — рост после fine-tuning).
\end{enumerate}

\textbf{Практическая ценность.}
\begin{itemize}\setlength\itemsep{0.25em}
    \item Открытый репозиторий содержит полный код, журналы и ноутбуки (\url{https://github.com/Innopolis-tensor-compression/tensor-compression-methods}), обеспечивая воспроизводимость и возможность дальнейшего расширения.
    \item Рекомендации по выбору библиотек, форматов и параметров пригодны для прикладных задач хранения, передачи и ускорения моделей и многомерных данных.
\end{itemize}

\textbf{Ограничения и направления будущих работ.}
\begin{itemize}\setlength\itemsep{0.25em}
    \item Улучшить функцию потерь и исследовать гибридные «глобальный + локальный» оптимизаторы ранга.
    \item Расширить конвейер на другие типы слоёв (групповые свёртки, attention) и форматы (Tensor Ring).
    \item Дополнить бенчмарк новыми наборами данных (аудио, гиперспектр) и библиотеками (EXATN, Scikit-TT).
\end{itemize}

Таким образом, работа вносит вклад в практику эффективного сжатия тензорных данных и моделей, предлагая как новые алгоритмы, так и документированную инфраструктуру для их оценки и применения.