\chapter{Заключение}
\label{chap:conclusion}
\chaptermark{Заключение}

\textbf{Основные достижения.} Бенчмарк 10 000+ уникальных прогонов на 3D–6D тензорах: измерены время, пиковая RAM/VRAM и ошибка Фробениуса. Выявлено, что TensorLy-TT обеспечивает оптимальный баланс точности и ресурсов; даны практические рекомендации по настройке гиперпараметров для CP, Tucker и TT; разработан \emph{алгоритм выбора ранга} для Tucker и Tensor-Train. Алгоритм на базе дифференциальной эволюции гарантирует заданное сжатие при минимальной ошибке Фробениуса; воссоздан и улучшен \emph{конвейер сжатия отдельных слоев нейронных сетей}. Для VGG и ResNet получено 4–8x уменьшение параметров и 14–22 \% ускорение инференса при падении Top-1 не более 1 pp (часто — рост после дообучения).

\textbf{Практическая ценность.} Открытый репозиторий содержит итоговый код реализаций, логи и ноутбуки с экспериментами (\url{https://github.com/Innopolis-tensor-compression/tensor-compression-methods}), обеспечивая воспроизводимость и возможность дальнейшего расширения; рекомендации по выбору библиотек, форматов и параметров пригодны для прикладных задач связанных с декомпозицией тензоров.

\textbf{Ограничения и направления будущих работ.} Улучшить функцию потерь и исследовать гибридные «глобальный + локальный» оптимизаторы ранга методов декомпозиции; расширить конвейер на другие типы слоёв; дополнить бенчмарк новыми наборами данных (аудио, гиперспектр) и библиотеками (EXATN, Scikit-TT).