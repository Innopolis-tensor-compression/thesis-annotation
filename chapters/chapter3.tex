\chapter{Обзор литературы}
\label{chap:lr}
\chaptermark{Обзор литературы}

В справочной части диссертации проанализированы четыре ключевые семьи тензорных разложений: \emph{CANDECOMP/PARAFAC} (CP), \emph{Tucker} (HOSVD), \emph{Tensor-Train} (TT) и \emph{Robust Tensor PCA} (RTPCA) как представитель устойчивых методов. Рассмотрены их математические основы, недавние усовершенствования и практические сценарии использования.

\subsection*{Классический инструментарий}

\begin{itemize}\setlength\itemsep{0.25em}
    \item \textbf{CP-разложение} (Hitchcock 1927; Carroll \& Chang 1970) аппроксимирует тензор суммой рангов-1, обеспечивая структурную интерпретируемость при условной уникальности представления. Основные проблемы: выбор ранга \(R\) и вычислительная устойчивость для высоких порядков.
    \item \textbf{Tucker/HOSVD} (Tucker 1966) разлагает тензор на компактное ядро \( \mathcal{G} \) и матрицы факторов \(\{A_n\}\) со свободными рангами \(R_n\) по модам. Гибкость даёт высокую точность и возможности денойзинга, но порождает неоднозначность факторов и сложность подбора рангов.
    \item \textbf{Tensor-Train (TT)} (Oseledets 2011) хранит данные цепочкой ядер и TT-рангов, переводя экспоненциальную сложность в линейную по порядку \(d\). Метод широко применяется для сжатия параметров нейросетей и решения многомерных уравнений.
\end{itemize}

\subsection*{Устойчивые и современные расширения}

\begin{itemize}\setlength\itemsep{0.25em}
    \item \textbf{Robust Barron-Loss Tucker} \cite{barron_loss_tensor_decomposition} заменяет норму Фробениуса обобщённой Barron-функцией, уменьшая влияние выбросов при сохранении управляемости гладкостью.
    \item \textbf{RTPCA} \cite{rtpca_method} сочетает ядерную норму и $\ell_1$-штраф для разделения низкоранковой структуры и разреженных выбросов. Эффективна в видео-денойзинге и медицинских данных.
\end{itemize}

\subsection*{Прикладные тенденции}

\begin{itemize}\setlength\itemsep{0.25em}
    \item \textbf{Компрессия CNN.}  
    \emph{Stable Low-rank Decomposition} \cite{stable_low_rank_tensor_decomposition} объединяет CP и Tucker для фильтров 3\(\times\)3 (VGG-16, ResNet-18), достигая лучшего баланса «точность–ускорение».  
    \emph{Hybrid TT + Hierarchical Tucker} \cite{hybrid_tensor_decomposition_c_nn} показывает, что разные форматы оптимальны для свёрточных и полносвязных слоёв соответственно.
    \item \textbf{Оптимизационные фреймворки.}  
    Работы \cite{yin2021efficienttensordecompositionbaseddnn} объединяют ADDM-регуляризацию, TT-разложение и дообучение, позволяя либо повысить точность, либо добиться экстремальных коэффициентов сжатия.
    \item \textbf{Масштабируемые аппроксимации.}  
    \emph{Cross Tensor Approximation} (CTA) \cite{cross_tensor_approximation} обходит полную SVD, используя выборку срезов/фибр и малое ядро; обеспечивает скорость и малый объём памяти для гиперспектральных и EEG-тензоров.
    \item \textbf{Временная разреженность.}  
    Time-aware разложения \cite{time_aware_tensor_decomposition} вводят динамический штраф по временной моде, сочетая аналитическое и итеративное обновления матриц факторов для эволюционирующих данных.
\end{itemize}

\subsection*{Выводы и выявленные пробелы}

Обзор показывает, что:

\begin{enumerate}\setlength\itemsep{0.25em}
    \item Выбор ранга остаётся главным фактором влияния на компромисс «точность–степень сжатия» и не решён универсально для Tucker и TT.  
    \item Современные библиотеки (TensorLy, tntorch, T3F и др.) различаются по API-зрелости и производительности; нет независимого бенчмарка, охватывающего 3D–6D тензоры разных типов.  
    \item Робастные формулировки (Barron-Loss, RTPCA) улучшают устойчивость, но требуют специализированных процедур ранжирования и ещё мало интегрированы в софт для нейросетей.
\end{enumerate}

Эти пробелы мотивируют практические задачи диссертации: (i) построить единый бенчмарк библиотек, (ii) разработать автоматический выбор ранга для Tucker и TT под заданное отношение сжатия, (iii) внедрить алгоритм в конвейер сжатия слоёв CNN и провести эмпирическую оценку.